\documentclass{article} 
\usepackage{geometry}
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }

 %\linespread{1.5}
\title{The Matchmakers: Data Analysis Report}

\author{
  D'Azevedo, Gloria\\
  \texttt{gad87@cornell.edu}
  \and
  Yadav, Pihu\\
  \texttt{py82@cornell.edu}
}
\date{November 25, 2016}

\begin{document}
\maketitle

%\section{Executive Summary}

%[To be written last]

\section{Introduction}
%Problem: 
The main goal of this analysis is to develop a model that predicts whether or not two people (a male and a female) will be attracted to one another.  In addition, we also want to find strong predictors of compatibility.  These predictors can be traits that a person has, activities that they enjoy, or how important is religion to the participant and their partner.  Some obvious applications for this model will be future speed dating events as well as online surveys that online dating websites or applications will use to determine potential matches for a participant. The ideal model could either work on both genders, and the model should be sparse or relatively small so that the surveys and forms (where we get data) will be shorter so people are more likely to complete the whole thing truthfully when they answer them.\\

The data used in the analysis is the Kaggle Speed Dating Experiment data set which was obtained from speed dating events conducted by Columbia Business School professors.  (https://www.kaggle.com/annavictoria/speed-dating-experiment). There are 21 different events (waves) that occur between October 2002 and April 2004, each of which have between 10 and 45 participants, and the number of men and women are roughly equal in each.  Each participant is required to fill out a total of 4 surveys in addition to questionnaires about their partners during the events.  The first survey occurs when they sign up, the second is halfway through the speed dating event, the third is the first follow-up the day after the speed dating event so that they will get a list of their matches, and the fourth is the second follow-up after the speed dating event which is sent 3-4 weeks after they had been sent their matches. \\

The types of questions asked on the survey are mostly ordinal or categorical variables with a couple of open-ended text questions.  It is noted that some of the open ended questions have a lower completion response rate such as the age field and also the school that you completed your undergraduate degree.  These fields therefore cannot be reliably used in the analysis because there could be inherent biases for why the participants did not respond. In the future, surveys can still ask these types of questions as a categorical or multiple-choice variable by giving participants a few age ranges that they can choose from so they would not be explicitly stating their age.  Relative age ranges can yield some information, which is better than no information.\\


\section{Data Cleaning Remarks}
During the following report we will take on the convention that a ``participant" is the person filling out the survey and the ``partner" is the person they interact with during that particular round of the speed dating wave.  When scraping data and analyzing the coefficients of the predictors in the model, we choose the participant to be female and the partner is male, so that the data is not double counted.  All females have interacted with each male once and vice versa so this is not a problem as there is only one incident of a person not completing her initial surveys.\\

At the beginning of the analysis, we noted that some cities and jobs had commas in them, so had to remove all those otherwise the comma delimiter during the import would break up all those fields and not import the correct value per column or the correct number of columns.  We also removed apostrophe's  or rewrote the word so that it would not need to be shortened with an apostrophe (i.e. changing ``Int'l" to ``International") since that seemed to cause import errors.\\

There were some blanks in the "pid" field that corresponded to the partner's id of the current participant for some of the id's in Wave 5. We deduced that the 7th female  didn't complete her responses to either the first survey or to the first follow up survey. Thus, we assume that she did not match with anyone and assign the "dec" and "dec\_0" fields which correspond to her decision to be 0. We chose not to delete all the corresponding rows entirely since they have information about male preferences for not matching with her.\\

%For the "int\_corr" field which is the correlation between the participant and the partner's ratings of interesting Time 1, we substitute the blanks for 0's to indicate that there is no correlation as we are not sure how the field is exactly calculated. If we decide to use a similar field, we can insert a new "correlation" column at the end of the data where we know the calculation deterministically.\\

In general, participants are asked in the surveys to divide up 100 points to 6 attributes by importance.  The attributes are attractivness, sincerity, intelligence, fun personality, ambition, and shared interests.  However, there are several questions where the shared interests are either not recorded in our data or the survey forgot that attribute when asking the participant.  It may be possible to impute that value for some participants if we assume that the question was asked on the survey but the data is not recorded by subtracting the sum of the points for the other attributes from 100 to get the points for the shared interests attribute as long as there is no non-response in the other questions.\\

Some fields are inter-related so if there are blank values in one of them, then the value cannot be found in the similar field. For example, there are two fields ``age\_o" and ``age". ``Age" is the self-reported age of the student and is asked when they signed up. ``age\_o" is the age of the partner during that round.  The values for ``age\_o" must have inputted after the survey was asked.  For example, if a participant did not report her age, the value for ``age\_o" for all the partners she had are also null.  The problem with age is that there are many possibilities why people did not report their true age.  For example, men tend to like young women, so women may report a lower age than the true value.  On the other hand, women prefer older, mature men as a measure of stability so men may report a higher age than the true value.  For now we did not edit or add any of the ``age" or ``age\_o" values, nor do we use them in the analysis but when we have to impute variables to implement the K-Nearest-Neighbors (KNN) on the data, then we impute the average age of the non-blank variables into the blankand NA values.\\

While investigating trends in categorical data such as the ``field\_cd" column (corresponds to a numerical code for the field of study that each person has) or ``race" (integer corresponding to a type of race), we noted that there were some NA values so we reassigned those NA values to be that predictor's ``Other" category.  Even though we would be over-counting the trends in the ``Other" category, we hope that the majority of participants had accurately written down their race.  If the data field was an ordinal variable such as ``tv" (measures the interest that a person has in watching TV on a scale from 1 to 10) we reassign NA values to be 0, indicating that they had no interest in that activity and that's why the participants left them blank.\\

Some of the survey fields requires a participant to rate their preferences about their partner; however, there are different instructions for this variable on the survey for different waves.  For example, during the initial survey before the events took place, the participants in waves 1-5 and 10-21 were asked to divide up 100 points among 6 different categories (more points implies higher importance).  In contrast, the participants in waves 6-9 were asked to rate each category on a scale of 1-10 for the importance of each attribute in a partner (a rating of 1 indicates that the attribute is not at all important while a rating of 10 is extremely important).  When we investigated the data by wave, the participants in waves 6-9 have also divided weights from 100 into the 6 attributes even though the key or instructions have said otherwise. Since each of the attribute weights are all on the same scale for all waves, the values did not need to be normalize the weights to the same scale.  The NA values were reassigned to be zeroes so that numerical calculations and the KNN algorithm can be performed although we also note that usually if there were NA values in one attribute, the other 5 attributes in that section were also missing.  There are many other fields that have weights or ranks as the expected input, so if the fields were not completed, (i.e. the participant left the field blank) then we reassign those blanks or NA values to be 0 indicating that the field is not important to them.\\

%Notice that there are a lot of non-responses for ranking attributes during the first follow-up survey in the section where the participants are asked to weight attributes that are important to them in the opposite sex.  We only have responses for a subset of few of the later waves (waves 15-21).

%For several waves (1-5, 12-14, and 21), there are no responses on the halfway point of the speed dating event where participants are asked to weight the importance of attributes in the opposite sex. In other waves there are several instances where there is no response but the majority of the others in those waves had responded.

\section{Initial Data Analysis and Methods}
%A suggestion from an outside source suggested that we create a field that groups the institutions that the students attended for their undergraduate degree together and see if that is a significant factor to whether or not two people will match.  We note that this field is pretty messy and has many blanks or NA's (around 40\% overall) so we do not think that we can reliably use this field as a predictor but potentially it can be used as a tie breaker when testing the model on new data.\\

%For some of the fields, the survey asks the participant what they think how other people rank several traits. However, it may not be that important to know what the participant thinks that other people prefer.  It is better to look at actual proof of what people value based on the traits of people that they liked during the speed dating event, regardless of whether or not the other person liked them back.  \\

%Importance of activities: 
In the initial sign-up survey, participants are asked how important each of 17 different activities are to them.  The activities include yoga, reading, and watching sports, and there may be high correlation between the interest level in some of the activities.  For example, a person who likes theater may also really enjoy watching movies.  These values are integer values from 0 to 10 and a higher value implies higher interest in the activity.  If two people have similar amounts of interest in the activity, then that should reflect in their classifications assuming that the participants do not mis-rank the interest level. We hypothesize that including similar levels of key interests should improve accuracy of classification.\\  

We tried fitting a linear model predicting match with all of the activities for both men and women (total of 34 variables) and taking only the significant variables from those to get a model.  In addition, we try using a forward/backward selection algorithm using AIC to find an optimal model using the activities.  Unfortunately we did not see that the same activities for both men and women were chosen so we will have to re-evaluate this method in future iteration.  We also will consider using a vector of absolute differences ($||\cdot||_1$) or the sum of squared differences ($||\cdot||_2^2$) between the interest level in an activity between two people. \\

In one of the initial analyses, we want to identify how men value different traits that they want in a partner (attractive, sincere, intelligent, fun, ambitious and having shared interests). We also include the parameter ``samerace" (which identifies whether the partner is of the same race) in the analysis. The results of this preliminary analysis suggested that attractiveness, sincerity, being fun, ambitious and having shared interests are significant in a man's decision and intelligence and being of the same race are not significant.  In this analysis all the values with missing data have been removed from the data when computing the coefficients for linear regression. Of these significant parameters, attractiveness, sincerity and shared interests are positively correlated with the final decision, but sincerity and ambition are negatively correlated with the male's decision. \\

In another preliminary analysis, we have studied the entire dataset (men and women) and use the scores given to different parameters such as attractiveness, sincerity, intelligence, being fun, ambitious and having shared interests by a participant to predict his or her decision. In this model we also consider the priorities assigned by participants to different variables and the interaction effects between the two. If people can correctly determine their priorities then there should be a direct correlation between the weighted scores given to a partner and the final decision (`yes' or `no').  Hence, our model is able to determine the most important factors in determining the final decision of a participant. The logistic regression used in this analysis suggests that the interaction between partner attractiveness and priority of attractiveness, sincerity, and several other factors are significant in determining a participant's decision.  Other parameters such as intelligence and fun are not significant to the model.  In the future we will also take precautions about using incomplete data and will detail the analysis accordingly.\\

%Rather than considering the priorities assigned to the individual parameters, we choose to compare the values of scores given to partners they said 'yes' to with the scores of all the partners. Initially we computed the summary statistics to get a broad idea of the difference between the two. Following this we performed a linear regression on the decision variable (dec) to determine which of the different parameters had the greatest impact on its value. The results of the regression suggest that while perceived attractiveness, sincerity, 'fun-ness', ambition and shared interests do play a role in deciding a man's decision, other factors such as intelligence, the partner being of the same race and actual shared interests do not play a major role.

 
\section{Model Development}
\subsection{K-Nearest-Neighbors (KNN)}
In order to implement the K-Nearest-Neighbors (KNN) algorithm to predict a match between two people, the data must not have any missing values nor can it use categorical variables.  Thus, some cleaning scripts were applied and some fields that had NA values were inputed to an ``Other" category or the field was some form of weights or rankings, the values were imputed to be 0 instead of missing, just for the application of this algorithm.  In addition, since there is relatively little data, a cross validation method is used to train and test the model on disjoint sections of data.

This method of reassigning or imputing may cause some bias in the data so we do not draw significant conclusions from this estimate.  However, it is important that we do not skew the other results by imputing an average or a most common value into some of the fields since it is possible that peopel who do not answer surveys have inherent traits in common so we want to try and bucket them together.  In addition, it may be the case that the algorithm does not yield the same result for a match depending on the view (male or female as the participant) which has a skewed interpretation so we also try to fit whether or not the participant ``likes" their partner.  In addition, another thing to note is that since their partner has to have a different gender than the participant, currently we have gender included in the KNN model fit, but that should never be the same for the participant and the partner so better results may be achieved if that field was not included.

Initial trials of KNN showed that a few number of nearest neighbors to implement KNN is too flexible and we have a high misclassification rate.  More tests are done to lower this number by increasing the number of nearest neighbors used and also using less fields in the algorithm.
\subsection{Best subset selection}
We have also implemented the best subset selection model, which studies all combinations of predictors for a given number of maximum predictors allowed in the model to determine the best possible combination. For this analysis we have used the previously studied variables such as scores given to a partner on the basis of attractiveness, sincerity, intelligence, being fun, ambitious and having shared interests, as well as other variables such as how much they liked the partner, the probability with which they think their partner will say yes to them, how happy they expect to be with the speed dating exercise, how often they go out (to see if extraverted behavior correlates with saying yes to more people), their goal behind attending the speed dating exercise, whether they have met the partner before and how often they go on dates. We have taken care to include only the variables that could have a correlation with the outcome and have disregarded those that have a large number of missing values. It was observed that most of the variables with a large number of missing values were responses to somewhat unrelated questions that would not be expected to have a correlation with the decision anyway. Hence we think our analysis should be quite accurate.

For a model containing a single predictor, the best one was found to be the score given for how much they liked the partner, this is clearly understandable as how much you like a person should have a very strong correlation with whether you say yes to them. For a model with two predictors, the best possible combination was found to be the score for how much they liked the partner and the score they gave for attractiveness of the partner. This is also clearly justifiable. Similiarly, best possible subset combinations were predicted for subsets containing just one variable to those containing all thirteen variables. The best subset among all possible combinations of predictors and number of predictors was found to be the one containing nine variables, which were the scores given to the partner for attractiveness, sincerity, being fun, ambitious, having shared interests as well as how much they liked the partner, the probability with which they expect their partner to say yes to them, the score for how often they go out and the one for how happy they expect to be with the speed dating exercise. 

While most of the predictors such as attractiveness, sincerity etc. are easy to justify, it is interesting to see that the people are more likely to say yes to a person when they think it is highly probable that their partner will say yes to them. Also, people who go out more often are also likely to say yes to more partners and people who expect to be happy with the speed dating exercise also say yes to more people. Perhaps there is a feedback loop in play, so people who expect the speed dating exercise to go well are able to find more people that they are interested in.



 
%\section{Results and Key Findings}

\section{Next Steps}
From the insights that we have gathered so far from our initial analysis, we have a set of predictors that we think are significant to our model.  These predictors are useful for determining whether or not two people will initially match, or at least if one person will like another person.  Since we also have information from follow-up surveys to the participant (a survey from the day after the speed dating event and another survey a few weeks after the first follow-up survey), we hope to use this information as another confirmation of the matches from the event.  The response rate for these follow-up surveys are lower than the initial sign-up survey and the survey halfway during the speed dating events since they require more effort to complete than the ones during the event, but hopefully there are enough responses to aggregate relatively accurately.  Also, some of the questions and responses for the follow-up surveys are very similar to questions that have already been asked to the participant such as how important are certain traits in the opposite gender or how does the participant think that they compare across others in terms of attractiveness and sincerity.  In theory, their responses should not change over time through the survey but we should run checks just in case.\\

In addition, so far when casually determining what predictors to use in the model, we have been using the full data set.  However, in practice it is best to divide up the data that we have into disjoint training and test data so that we can train different models on the training data and then test the model on new data to get a more accurate estimate of test error.  We have already developed a function to use the boostrap method for resampling but that can also create biases and overfit the data.  Another method that we will try is the k-fold cross validation method to compute the error rate or number of misclassifications.  Since we only have around 8,000 data points in total, we could theoretically also try a Leave-One-Out-Cross-Validation (LOOCV) method which is a special case of k-fold cross validation where k is equal to the total number of data points.\\



\end{document}
